{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autotime\n",
    "import numpy as np\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39963.59\n",
      "time: 2.93 s\n"
     ]
    }
   ],
   "source": [
    "a=np.genfromtxt('data_for_clustering.csv', delimiter=',')\n",
    "a=a[:-1]\n",
    "print(a[1])\n",
    "x=a[:250*910]\n",
    "x=x[20*250:]\n",
    "x=x.reshape(-1,250)\n",
    "me=np.mean(x,axis=1)\n",
    "x=(x.T-me).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 71.8 ms\n"
     ]
    }
   ],
   "source": [
    "encoding_dim = 10\n",
    " \n",
    "# this is our input placeholder\n",
    "input_img = Input(shape=(250,))\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "encoded = Dense(encoding_dim, activation='linear')(input_img)\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "decoded = Dense(250, activation='linear')(encoded)\n",
    "# this model maps an input to its reconstruction\n",
    "autoencoder = Model(input_img, decoded)\n",
    "# this model maps an input to its encoded representation\n",
    "encoder = Model(input_img, encoded)\n",
    "# create a placeholder for an encoded (10-dimensional) input\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "# retrieve the last layer of the autoencoder model\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "# create the decoder model\n",
    "decoder = Model(encoded_input, decoder_layer(encoded_input))\n",
    "autoencoder.compile(optimizer='adam', loss='mse')#binary_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "890/890 [==============================] - 1s 1ms/step - loss: 45103.7802\n",
      "Epoch 2/50\n",
      "890/890 [==============================] - 0s 277us/step - loss: 29854.8858\n",
      "Epoch 3/50\n",
      "890/890 [==============================] - 0s 259us/step - loss: 25035.4675\n",
      "Epoch 4/50\n",
      "890/890 [==============================] - 0s 251us/step - loss: 21951.3005\n",
      "Epoch 5/50\n",
      "890/890 [==============================] - 0s 258us/step - loss: 19464.9473\n",
      "Epoch 6/50\n",
      "890/890 [==============================] - 0s 253us/step - loss: 17620.0083\n",
      "Epoch 7/50\n",
      "890/890 [==============================] - 0s 248us/step - loss: 16531.2852\n",
      "Epoch 8/50\n",
      "890/890 [==============================] - 0s 254us/step - loss: 15908.7597\n",
      "Epoch 9/50\n",
      "890/890 [==============================] - 0s 245us/step - loss: 15544.8318\n",
      "Epoch 10/50\n",
      "890/890 [==============================] - 0s 245us/step - loss: 15327.5864\n",
      "Epoch 11/50\n",
      "890/890 [==============================] - 0s 254us/step - loss: 15178.0229\n",
      "Epoch 12/50\n",
      "890/890 [==============================] - 0s 251us/step - loss: 15077.5077\n",
      "Epoch 13/50\n",
      "890/890 [==============================] - 0s 254us/step - loss: 14993.9295\n",
      "Epoch 14/50\n",
      "890/890 [==============================] - 0s 259us/step - loss: 14950.4506\n",
      "Epoch 15/50\n",
      "890/890 [==============================] - 0s 259us/step - loss: 14899.8335\n",
      "Epoch 16/50\n",
      "890/890 [==============================] - 0s 250us/step - loss: 14871.6008\n",
      "Epoch 17/50\n",
      "890/890 [==============================] - 0s 240us/step - loss: 14824.4222\n",
      "Epoch 18/50\n",
      "890/890 [==============================] - 0s 241us/step - loss: 14803.8138\n",
      "Epoch 19/50\n",
      "890/890 [==============================] - 0s 255us/step - loss: 14766.1418\n",
      "Epoch 20/50\n",
      "890/890 [==============================] - 0s 244us/step - loss: 14742.4563\n",
      "Epoch 21/50\n",
      "890/890 [==============================] - 0s 242us/step - loss: 14715.4904\n",
      "Epoch 22/50\n",
      "890/890 [==============================] - 0s 252us/step - loss: 14723.4517\n",
      "Epoch 23/50\n",
      "890/890 [==============================] - 0s 246us/step - loss: 14697.3284\n",
      "Epoch 24/50\n",
      "890/890 [==============================] - 0s 252us/step - loss: 14683.2542\n",
      "Epoch 25/50\n",
      "890/890 [==============================] - 0s 248us/step - loss: 14678.1025\n",
      "Epoch 26/50\n",
      "890/890 [==============================] - 0s 239us/step - loss: 14670.6608\n",
      "Epoch 27/50\n",
      "890/890 [==============================] - 0s 240us/step - loss: 14654.3765\n",
      "Epoch 28/50\n",
      "890/890 [==============================] - 0s 243us/step - loss: 14638.4423\n",
      "Epoch 29/50\n",
      "890/890 [==============================] - 0s 239us/step - loss: 14646.8212\n",
      "Epoch 30/50\n",
      "890/890 [==============================] - 0s 243us/step - loss: 14649.3458\n",
      "Epoch 31/50\n",
      "890/890 [==============================] - 0s 266us/step - loss: 14639.8111\n",
      "Epoch 32/50\n",
      "890/890 [==============================] - 0s 247us/step - loss: 14628.4553\n",
      "Epoch 33/50\n",
      "890/890 [==============================] - 0s 245us/step - loss: 14640.7186\n",
      "Epoch 34/50\n",
      "890/890 [==============================] - 0s 240us/step - loss: 14624.8824\n",
      "Epoch 35/50\n",
      "890/890 [==============================] - 0s 255us/step - loss: 14624.3449\n",
      "Epoch 36/50\n",
      "890/890 [==============================] - 0s 241us/step - loss: 14626.2134\n",
      "Epoch 37/50\n",
      "890/890 [==============================] - 0s 243us/step - loss: 14633.0143\n",
      "Epoch 38/50\n",
      "890/890 [==============================] - 0s 243us/step - loss: 14647.4013\n",
      "Epoch 39/50\n",
      "890/890 [==============================] - 0s 272us/step - loss: 14634.4981\n",
      "Epoch 40/50\n",
      "890/890 [==============================] - 0s 259us/step - loss: 14612.4807\n",
      "Epoch 41/50\n",
      "890/890 [==============================] - 0s 241us/step - loss: 14611.6821\n",
      "Epoch 42/50\n",
      "890/890 [==============================] - 0s 245us/step - loss: 14616.1248\n",
      "Epoch 43/50\n",
      "890/890 [==============================] - 0s 269us/step - loss: 14602.8465\n",
      "Epoch 44/50\n",
      "890/890 [==============================] - 0s 255us/step - loss: 14605.2389\n",
      "Epoch 45/50\n",
      "890/890 [==============================] - 0s 263us/step - loss: 14602.9010\n",
      "Epoch 46/50\n",
      "890/890 [==============================] - 0s 268us/step - loss: 14625.0124\n",
      "Epoch 47/50\n",
      "890/890 [==============================] - 0s 235us/step - loss: 14599.8972\n",
      "Epoch 48/50\n",
      "890/890 [==============================] - 0s 238us/step - loss: 14596.8816\n",
      "Epoch 49/50\n",
      "890/890 [==============================] - 0s 259us/step - loss: 14620.4821\n",
      "Epoch 50/50\n",
      "890/890 [==============================] - 0s 268us/step - loss: 14592.6089\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12fbd8ec9b0>"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 12.3 s\n"
     ]
    }
   ],
   "source": [
    "autoencoder.fit(x,x,\n",
    "epochs=50,\n",
    "batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 604 ms\n"
     ]
    }
   ],
   "source": [
    "encoded_layer=encoder.predict(x)\n",
    "decoded_output=decoder.predict(encoded_layer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  595.9482  ,   454.91803 , -1147.4452  ,  -606.3856  ,\n",
       "        -226.27493 ,   628.6242  ,   -65.97828 ,   -13.330373,\n",
       "        -159.09267 ,   734.2386  ], dtype=float32)"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.99 ms\n"
     ]
    }
   ],
   "source": [
    "encoded_layer[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-283.82984 -320.26984 -352.82984 -368.53984 -363.54984 -345.42984\n",
      " -326.71984 -323.58984 -343.53984 -379.39984 -415.02984 -428.66984\n",
      " -406.26984 -343.71984 -250.90984 -148.18984  -57.67984    4.44016\n",
      "   33.73016   37.16016   31.09016   32.81016   52.25016   91.81016\n",
      "  145.80016  204.82016  259.72016  302.54016  330.46016  342.92016\n",
      "  340.25016  324.33016  294.53016  252.03016  199.36016  143.42016\n",
      "   94.62016   61.20016   49.06016   61.63016   96.82016  148.47016\n",
      "  206.60016  263.34016  311.97016  349.27016  375.44016  391.86016\n",
      "  401.31016  405.74016  406.60016  403.17016  392.42016  371.62016\n",
      "  340.80016  303.83016  266.81016  234.81016  211.58016  197.41016\n",
      "  186.76016  172.81016  147.65016  111.40016   71.90016   42.87016\n",
      "   37.65016   63.79016  119.32016  193.63016  269.71016  330.18016\n",
      "  361.84016  362.98016  341.71016  310.47016  280.34016  253.74016\n",
      "  226.53016  190.29016  135.08016   58.11016  -34.62984 -129.62984\n",
      " -208.08984 -254.40984 -260.47984 -233.70984 -188.50984 -140.77984\n",
      " -105.03984  -86.42984  -84.04984  -91.01984  -98.58984  -99.56984\n",
      "  -90.09984  -73.44984  -55.17984  -38.81984  -26.87984  -19.71984\n",
      "  -19.65984  -27.72984  -45.32984  -73.82984 -112.38984 -156.82984\n",
      " -198.62984 -228.51984 -238.46984 -223.32984 -188.60984 -146.95984\n",
      " -111.82984  -96.01984 -103.66984 -132.53984 -174.77984 -215.50984\n",
      " -241.46984 -241.30984 -213.03984 -161.41984  -95.46984  -28.22984\n",
      "   30.02016   71.08016   91.67016   93.19016   77.97016   49.83016\n",
      "    8.28016  -46.65984 -114.86984 -191.62984 -267.49984 -334.46984\n",
      " -384.13984 -411.91984 -419.31984 -410.39984 -394.14984 -378.36984\n",
      " -366.61984 -354.43984 -332.29984 -291.16984 -224.76984 -131.90984\n",
      "  -21.75984   89.10016  181.30016  237.28016  247.42016  213.25016\n",
      "  146.69016   65.88016   -9.18984  -61.90984  -84.46984  -75.80984\n",
      "  -44.47984   -2.18984   40.74016   75.76016  100.17016  113.06016\n",
      "  119.31016  126.47016  137.63016  155.85016  179.71016  204.70016\n",
      "  226.81016  244.07016  253.73016  253.34016  240.12016  214.18016\n",
      "  176.96016  129.78016   75.64016   18.99016  -34.61984  -78.56984\n",
      " -105.20984 -111.75984  -96.49984  -61.20984  -11.83984   44.57016\n",
      "   98.42016  141.02016  165.07016  170.48016  164.55016  155.67016\n",
      "  149.24016  148.19016  151.68016  156.59016  157.23016  147.19016\n",
      "  123.07016   87.95016   50.09016   17.73016   -2.08984   -7.10984\n",
      "   -1.44984    6.31016    4.29016  -17.15984  -57.21984 -107.88984\n",
      " -154.49984 -181.14984 -175.82984 -137.13984  -77.44984  -11.30984\n",
      "   45.02016   78.89016   88.18016   78.64016   62.13016   50.69016\n",
      "   51.14016   62.35016   75.74016   83.78016   78.59016   57.02016\n",
      "   21.18016  -25.08984  -76.24984 -129.91984 -186.41984 -246.42984\n",
      " -308.25984 -364.15984 -404.66984 -419.35984 -401.97984 -355.39984\n",
      " -286.88984 -211.98984 -146.63984 -100.55984]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-3.39386787e+01, -6.39701195e+01, -9.90576324e+01, -1.37393646e+02,\n",
       "       -1.76417511e+02, -2.13639771e+02, -2.47349213e+02, -2.76652618e+02,\n",
       "       -3.01027130e+02, -3.19681488e+02, -3.31433624e+02, -3.34580597e+02,\n",
       "       -3.26819153e+02, -3.06598022e+02, -2.73309204e+02, -2.27724731e+02,\n",
       "       -1.71948395e+02, -1.09892021e+02, -4.64200401e+01,  1.42259521e+01,\n",
       "        6.87396545e+01,  1.14740082e+02,  1.50800430e+02,  1.75417038e+02,\n",
       "        1.88170273e+02,  1.88965134e+02,  1.78703873e+02,  1.58817093e+02,\n",
       "        1.31966705e+02,  1.01233246e+02,  7.01035004e+01,  4.18281784e+01,\n",
       "        1.92588367e+01,  4.18489027e+00, -2.32867861e+00,  8.67995620e-02,\n",
       "        1.11208754e+01,  2.96224747e+01,  5.48742104e+01,  8.56604538e+01,\n",
       "        1.21234795e+02,  1.60259750e+02,  2.01129318e+02,  2.42584122e+02,\n",
       "        2.83166779e+02,  3.21319153e+02,  3.55405487e+02,  3.84219025e+02,\n",
       "        4.06696442e+02,  4.21984558e+02,  4.29052582e+02,  4.26587585e+02,\n",
       "        4.14008453e+02,  3.90933319e+02,  3.57716797e+02,  3.15582916e+02,\n",
       "        2.67438354e+02,  2.17557129e+02,  1.70649078e+02,  1.31227341e+02,\n",
       "        1.02762978e+02,  8.69132996e+01,  8.37055054e+01,  9.11708832e+01,\n",
       "        1.06373032e+02,  1.25952896e+02,  1.48095886e+02,  1.72006317e+02,\n",
       "        1.97612656e+02,  2.25207703e+02,  2.54315201e+02,  2.83307892e+02,\n",
       "        3.09214569e+02,  3.29008698e+02,  3.39819000e+02,  3.39189880e+02,\n",
       "        3.26386322e+02,  3.02149445e+02,  2.68614441e+02,  2.28551895e+02,\n",
       "        1.84605087e+02,  1.38698044e+02,  9.21141434e+01,  4.60144463e+01,\n",
       "        1.68064189e+00, -3.93898354e+01, -7.52441711e+01, -1.03996826e+02,\n",
       "       -1.24036530e+02, -1.34765656e+02, -1.36762787e+02, -1.31745331e+02,\n",
       "       -1.21890373e+02, -1.09517090e+02, -9.64512100e+01, -8.36660995e+01,\n",
       "       -7.15040588e+01, -5.96138191e+01, -4.81391678e+01, -3.78917122e+01,\n",
       "       -3.06067581e+01, -2.84558430e+01, -3.37643318e+01, -4.79889870e+01,\n",
       "       -7.13267365e+01, -1.02217384e+02, -1.37897217e+02, -1.74988327e+02,\n",
       "       -2.10129135e+02, -2.40485626e+02, -2.64812439e+02, -2.83144348e+02,\n",
       "       -2.96140198e+02, -3.05111481e+02, -3.10732391e+02, -3.12465820e+02,\n",
       "       -3.09152893e+02, -2.99622253e+02, -2.83348724e+02, -2.60767120e+02,\n",
       "       -2.33689499e+02, -2.04492615e+02, -1.75937622e+02, -1.50553864e+02,\n",
       "       -1.30264160e+02, -1.15767197e+02, -1.06726479e+02, -1.02682961e+02,\n",
       "       -1.03390343e+02, -1.08771042e+02, -1.18985329e+02, -1.33780716e+02,\n",
       "       -1.52636673e+02, -1.74320740e+02, -1.96846146e+02, -2.17844574e+02,\n",
       "       -2.35540421e+02, -2.48521652e+02, -2.56210297e+02, -2.58653809e+02,\n",
       "       -2.56208405e+02, -2.48379883e+02, -2.34055527e+02, -2.11580093e+02,\n",
       "       -1.79782852e+02, -1.39263733e+02, -9.23349686e+01, -4.31707611e+01,\n",
       "        3.17343616e+00,  4.23066406e+01,  7.14627686e+01,  9.01260605e+01,\n",
       "        9.94913101e+01,  1.02283417e+02,  1.01339188e+02,  9.79625244e+01,\n",
       "        9.24001236e+01,  8.31042633e+01,  6.84140472e+01,  4.73234329e+01,\n",
       "        2.06322136e+01, -8.33737850e+00, -3.54471703e+01, -5.61339264e+01,\n",
       "       -6.75192719e+01, -6.82033768e+01, -5.90116692e+01, -4.15804520e+01,\n",
       "       -1.80689716e+01,  9.71353245e+00,  4.05429688e+01,  7.34630966e+01,\n",
       "        1.07713501e+02,  1.41610458e+02,  1.72993454e+02,  1.98925323e+02,\n",
       "        2.17097763e+02,  2.25806152e+02,  2.24623505e+02,  2.14315948e+02,\n",
       "        1.96100037e+02,  1.71735779e+02,  1.43034515e+02,  1.11630287e+02,\n",
       "        7.92478333e+01,  4.80111923e+01,  2.02882519e+01, -1.15423930e+00,\n",
       "       -1.40275698e+01, -1.65636654e+01, -8.99479485e+00,  7.06879473e+00,\n",
       "        2.89555302e+01,  5.38500023e+01,  7.94784851e+01,  1.04845161e+02,\n",
       "        1.29475098e+02,  1.53384201e+02,  1.76654663e+02,  1.98881622e+02,\n",
       "        2.18353516e+02,  2.32161972e+02,  2.37607208e+02,  2.33073273e+02,\n",
       "        2.18280731e+02,  1.94485382e+02,  1.63856964e+02,  1.28864731e+02,\n",
       "        9.13980484e+01,  5.22702446e+01,  1.19445181e+01, -2.93164120e+01,\n",
       "       -7.02085953e+01, -1.08761230e+02, -1.41836868e+02, -1.65905380e+02,\n",
       "       -1.77908264e+02, -1.76378525e+02, -1.62010971e+02, -1.37410690e+02,\n",
       "       -1.06977669e+02, -7.50945740e+01, -4.54074326e+01, -2.01478996e+01,\n",
       "       -8.39652121e-02,  1.53121042e+01,  2.66698399e+01,  3.44448128e+01,\n",
       "        3.81552467e+01,  3.69070663e+01,  2.98205547e+01,  1.58779640e+01,\n",
       "       -5.12446213e+00, -3.22577515e+01, -6.42141037e+01, -9.98155365e+01,\n",
       "       -1.37069855e+02, -1.72633865e+02, -2.03788925e+02, -2.28162354e+02,\n",
       "       -2.44239975e+02, -2.50910385e+02, -2.47836777e+02, -2.36027939e+02,\n",
       "       -2.16909958e+02, -1.92551193e+02, -1.64905823e+02, -1.35442368e+02,\n",
       "       -1.04937668e+02, -7.37436218e+01], dtype=float32)"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 15 ms\n"
     ]
    }
   ],
   "source": [
    "print(x[0])\n",
    "decoded_output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "621f4060292b49a69e36a1d17a75f44b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x12fa37d5cc0>]"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 29.9 ms\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib widget\n",
    "q=5\n",
    "plt.plot(range(250),x[q],label=1)\n",
    "plt.plot(range(250),decoded_output[q],label=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <function LineWatcher.stop at 0x0000012ED0E22840> (for post_run_cell):\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\backcall\\backcall.py\u001b[0m in \u001b[0;36madapted\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    102\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[1;31m#            print(args, kwargs, unmatched_pos, cut_positional, unmatched_kw)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 104\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    105\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0madapted\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\autotime.py\u001b[0m in \u001b[0;36mstop\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart_time\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m             \u001b[0mdiff\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m             \u001b[1;32massert\u001b[0m \u001b[0mdiff\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'time: %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mformat_delta\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdiff\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#np.savetxt('compressed_data.csv',encoded_layer,delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_dim = 10\n",
    " \n",
    "# this is our input placeholder\n",
    "input_img = Input(shape=(250,))\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "encoded0=Dense(100,activation='linear')(input_img)\n",
    "encoded = Dense(encoding_dim, activation='linear')(encoded0)\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "decoded0=Dense(100,activation='linear')(encoded)\n",
    "decoded = Dense(250, activation='linear')(decoded0)\n",
    "# this model maps an input to its reconstruction\n",
    "autoencoder = Model(input_img, decoded)\n",
    "# this model maps an input to its encoded representation\n",
    "encoder = Model(input_img, encoded)\n",
    "# create a placeholder for an encoded (10-dimensional) input\n",
    "encoded_input = Input(shape=(100,))\n",
    "# retrieve the last layer of the autoencoder model\n",
    "decoder_layer = autoencoder.layers[-2]\n",
    "# create the decoder model\n",
    "decoder = Model(encoded_input, decoder_layer(encoded_input))\n",
    "autoencoder.compile(optimizer='adam', loss='mse')#binary_crossentropy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
