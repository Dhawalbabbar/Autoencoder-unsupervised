{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autotime\n",
    "import numpy as np\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39963.59\n",
      "9067.127637781465\n",
      "30896.46236221853\n",
      "(228260,)\n",
      "0.3929558925410532 0.392377741792573\n",
      "0.3929558925410532 0.392377741792573\n",
      "time: 2.48 s\n"
     ]
    }
   ],
   "source": [
    "a=np.genfromtxt('data_for_clustering.csv', delimiter=',')\n",
    "a=a[:-1]\n",
    "print(a[1])\n",
    "m=np.mean(a)\n",
    "a=a-m\n",
    "print(a[1])\n",
    "print(m)\n",
    "print(a.shape)\n",
    "x=a[:250*910]\n",
    "RANGE=np.max(x)-np.min(x)\n",
    "x=x/RANGE\n",
    "print(x[0],x[1])\n",
    "x=x.reshape(-1,250)\n",
    "print(x[0][0],x[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 72.8 ms\n"
     ]
    }
   ],
   "source": [
    "encoding_dim = 10 # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
    " \n",
    "# this is our input placeholder\n",
    "input_img = Input(shape=(250,))\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "encoded = Dense(encoding_dim, activation='linear')(input_img)\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "decoded = Dense(250, activation='linear')(encoded)\n",
    "# this model maps an input to its reconstruction\n",
    "autoencoder = Model(input_img, decoded)\n",
    "# this model maps an input to its encoded representation\n",
    "encoder = Model(input_img, encoded)\n",
    "# create a placeholder for an encoded (32-dimensional) input\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "# retrieve the last layer of the autoencoder model\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "# create the decoder model\n",
    "decoder = Model(encoded_input, decoder_layer(encoded_input))\n",
    "# configure our model to use a per-pixel binary crossentropy loss, and the Adadelta optimizer:\n",
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "910/910 [==============================] - 1s 708us/step - loss: -0.9385\n",
      "Epoch 2/50\n",
      "910/910 [==============================] - 0s 285us/step - loss: -1.2312\n",
      "Epoch 3/50\n",
      "910/910 [==============================] - 0s 258us/step - loss: -1.3106\n",
      "Epoch 4/50\n",
      "910/910 [==============================] - 0s 256us/step - loss: -1.3336\n",
      "Epoch 5/50\n",
      "910/910 [==============================] - 0s 255us/step - loss: -1.3453\n",
      "Epoch 6/50\n",
      "910/910 [==============================] - 0s 271us/step - loss: -1.3486\n",
      "Epoch 7/50\n",
      "910/910 [==============================] - 0s 259us/step - loss: -1.3589\n",
      "Epoch 8/50\n",
      "910/910 [==============================] - 0s 262us/step - loss: -1.3595\n",
      "Epoch 9/50\n",
      "910/910 [==============================] - 0s 263us/step - loss: -1.3596\n",
      "Epoch 10/50\n",
      "910/910 [==============================] - 0s 264us/step - loss: -1.3597\n",
      "Epoch 11/50\n",
      "910/910 [==============================] - 0s 258us/step - loss: -1.3597\n",
      "Epoch 12/50\n",
      "910/910 [==============================] - 0s 255us/step - loss: -1.3597\n",
      "Epoch 13/50\n",
      "910/910 [==============================] - 0s 260us/step - loss: -1.3597\n",
      "Epoch 14/50\n",
      "910/910 [==============================] - 0s 264us/step - loss: -1.3597\n",
      "Epoch 15/50\n",
      "910/910 [==============================] - 0s 259us/step - loss: -1.3597\n",
      "Epoch 16/50\n",
      "910/910 [==============================] - 0s 259us/step - loss: -1.3597\n",
      "Epoch 17/50\n",
      "910/910 [==============================] - 0s 265us/step - loss: -1.3597\n",
      "Epoch 18/50\n",
      "910/910 [==============================] - 0s 259us/step - loss: -1.3598\n",
      "Epoch 19/50\n",
      "910/910 [==============================] - 0s 262us/step - loss: -1.3598\n",
      "Epoch 20/50\n",
      "910/910 [==============================] - 0s 260us/step - loss: -1.3598\n",
      "Epoch 21/50\n",
      "910/910 [==============================] - 0s 260us/step - loss: -1.3598\n",
      "Epoch 22/50\n",
      "910/910 [==============================] - 0s 258us/step - loss: -1.3598\n",
      "Epoch 23/50\n",
      "910/910 [==============================] - 0s 269us/step - loss: -1.3598\n",
      "Epoch 24/50\n",
      "910/910 [==============================] - 0s 263us/step - loss: -1.3598\n",
      "Epoch 25/50\n",
      "910/910 [==============================] - 0s 270us/step - loss: -1.3598\n",
      "Epoch 26/50\n",
      "910/910 [==============================] - 0s 277us/step - loss: -1.3598\n",
      "Epoch 27/50\n",
      "910/910 [==============================] - 0s 281us/step - loss: -1.3598\n",
      "Epoch 28/50\n",
      "910/910 [==============================] - 0s 269us/step - loss: -1.3598\n",
      "Epoch 29/50\n",
      "910/910 [==============================] - 0s 271us/step - loss: -1.3598\n",
      "Epoch 30/50\n",
      "910/910 [==============================] - 0s 270us/step - loss: -1.3598\n",
      "Epoch 31/50\n",
      "910/910 [==============================] - 0s 278us/step - loss: -1.3598\n",
      "Epoch 32/50\n",
      "910/910 [==============================] - 0s 272us/step - loss: -1.3598\n",
      "Epoch 33/50\n",
      "910/910 [==============================] - 0s 277us/step - loss: -1.3598\n",
      "Epoch 34/50\n",
      "910/910 [==============================] - 0s 267us/step - loss: -1.3598\n",
      "Epoch 35/50\n",
      "910/910 [==============================] - 0s 273us/step - loss: -1.3598\n",
      "Epoch 36/50\n",
      "910/910 [==============================] - 0s 261us/step - loss: -1.3598\n",
      "Epoch 37/50\n",
      "910/910 [==============================] - 0s 259us/step - loss: -1.3599\n",
      "Epoch 38/50\n",
      "910/910 [==============================] - 0s 255us/step - loss: -1.3599\n",
      "Epoch 39/50\n",
      "910/910 [==============================] - 0s 260us/step - loss: -1.3599\n",
      "Epoch 40/50\n",
      "910/910 [==============================] - 0s 264us/step - loss: -1.3598\n",
      "Epoch 41/50\n",
      "910/910 [==============================] - 0s 263us/step - loss: -1.3599\n",
      "Epoch 42/50\n",
      "910/910 [==============================] - 0s 263us/step - loss: -1.3599\n",
      "Epoch 43/50\n",
      "910/910 [==============================] - 0s 261us/step - loss: -1.3599\n",
      "Epoch 44/50\n",
      "910/910 [==============================] - 0s 266us/step - loss: -1.3599\n",
      "Epoch 45/50\n",
      "910/910 [==============================] - 0s 264us/step - loss: -1.3599\n",
      "Epoch 46/50\n",
      "910/910 [==============================] - 0s 264us/step - loss: -1.3599\n",
      "Epoch 47/50\n",
      "910/910 [==============================] - 0s 262us/step - loss: -1.3599\n",
      "Epoch 48/50\n",
      "910/910 [==============================] - 0s 269us/step - loss: -1.3599\n",
      "Epoch 49/50\n",
      "910/910 [==============================] - 0s 261us/step - loss: -1.3599\n",
      "Epoch 50/50\n",
      "910/910 [==============================] - 0s 264us/step - loss: -1.3599\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2e293779dd8>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 12.7 s\n"
     ]
    }
   ],
   "source": [
    "autoencoder.fit(x,x,\n",
    "epochs=50,\n",
    "batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 250 ms\n"
     ]
    }
   ],
   "source": [
    "encoded_layer=encoder.predict(x)\n",
    "decoded_output=decoder.predict(encoded_layer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.9847087, -0.8469611, -1.2722908, -1.7237288, -0.5095168,\n",
       "        1.2887869, -2.8750024, -1.4604946,  1.7509706, -1.2280377],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.99 ms\n"
     ]
    }
   ],
   "source": [
    "encoded_layer[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.39295589 0.39237774 0.39261792 0.39416845 0.39715744 0.40110366\n",
      " 0.40508624 0.40815918 0.4096924  0.40956258 0.40818731 0.40641737\n",
      " 0.40495079 0.4043272  0.4046933  0.40560857 0.40642862 0.40651907\n",
      " 0.40545018 0.40316484 0.40003478 0.39669483 0.3938348  0.39200904\n",
      " 0.39149926 0.39223667 0.39388111 0.39581506 0.39746079 0.39832672\n",
      " 0.3981493  0.3970908  0.39562508 0.39432164 0.3936167  0.39361973\n",
      " 0.39413513 0.39481108 0.39528581 0.39530095 0.39480502 0.39403084\n",
      " 0.39329517 0.39290786 0.39299744 0.39341417 0.39394126 0.39434112\n",
      " 0.39449604 0.39442291 0.39421043 0.39402218 0.39393433 0.39397804\n",
      " 0.39407325 0.39421129 0.39448782 0.39506251 0.39610716 0.39759884\n",
      " 0.39929954 0.4007592  0.40144424 0.40107251 0.39968166 0.39762827\n",
      " 0.39566446 0.39455057 0.39476348 0.39631185 0.39864349 0.40100197\n",
      " 0.40279571 0.40373693 0.40393729 0.40375468 0.40372308 0.40412467\n",
      " 0.4049166  0.40579724 0.40626634 0.40606338 0.40524982 0.4041567\n",
      " 0.40321461 0.4026001  0.40229329 0.40215654 0.40191593 0.40146025\n",
      " 0.40087777 0.40051123 0.40075833 0.40173548 0.4031722  0.40439471\n",
      " 0.40457906 0.40328125 0.40059475 0.39716566 0.39387548 0.39155725\n",
      " 0.39067099 0.39100204 0.3918896  0.39246083 0.39208434 0.39074369\n",
      " 0.38891576 0.38737345 0.38670615 0.3871138  0.3882688  0.38954627\n",
      " 0.39030748 0.39024819 0.38963975 0.38908021 0.38935933 0.39100939\n",
      " 0.39396506 0.39772391 0.40150136 0.40459377 0.40662466 0.4076031\n",
      " 0.40793891 0.40812889 0.40849975 0.40913719 0.40969457 0.40980578\n",
      " 0.40928043 0.40817303 0.40677439 0.40533723 0.40407448 0.40302939\n",
      " 0.40201763 0.40074924 0.39899575 0.39688264 0.39486561 0.39354659\n",
      " 0.39323848 0.39384908 0.39492879 0.39578563 0.3957575  0.39452027\n",
      " 0.39219642 0.38945843 0.38734619 0.38679573 0.38821125 0.39124394\n",
      " 0.39493571 0.39807703 0.39965266 0.39912038 0.39666281 0.39309654\n",
      " 0.38947054 0.38672303 0.38542306 0.38543907 0.38636947 0.38761319\n",
      " 0.38866304 0.3892784  0.3894277  0.3891568  0.3884908  0.38742235\n",
      " 0.38600077 0.3842356  0.38239642 0.3809545  0.38048454 0.38136259\n",
      " 0.38358128 0.38670788 0.39004437 0.3929031  0.39480113 0.39558786\n",
      " 0.39547621 0.39490282 0.39429265 0.39387072 0.39356607 0.39317659\n",
      " 0.39267807 0.39215185 0.39177276 0.39170525 0.39190172 0.39205318\n",
      " 0.39176584 0.39066363 0.38840036 0.38527722 0.38232934 0.38072385\n",
      " 0.38132321 0.38449308 0.38974144 0.39584492 0.40129407 0.40473398\n",
      " 0.40551163 0.4039334  0.40106255 0.39830552 0.39697525 0.39778016\n",
      " 0.40061726 0.40467253 0.40882734 0.41213353 0.41397314 0.41421115\n",
      " 0.4130198  0.41076389 0.40793112 0.40477899 0.40165628 0.39884948\n",
      " 0.39664766 0.39529533 0.39476737 0.39492749 0.39540611 0.3957575\n",
      " 0.39574149 0.39519709 0.39416932 0.39293382 0.39171218 0.39068916\n",
      " 0.38973582 0.38866953 0.38751409 0.38633485 0.38536983 0.3848501\n",
      " 0.38483279 0.38521664 0.38577834 0.38624701]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.3891928 ,  0.4015348 ,  0.39766273,  0.3968355 ,  0.39853364,\n",
       "        0.39329794,  0.39236408,  0.40134063,  0.40224338,  0.39670306,\n",
       "        0.39909902,  0.3928712 ,  0.40234524,  0.3944338 ,  0.39872026,\n",
       "        0.3948511 ,  0.39656025,  0.3907128 ,  0.39355627,  0.39836836,\n",
       "        0.400936  ,  0.39526778,  0.39637756,  0.4015198 ,  0.40550002,\n",
       "        0.3905538 ,  0.39471778,  0.40628833,  0.391758  ,  0.39453334,\n",
       "        0.39618918,  0.39695492,  0.39890704,  0.3884227 ,  0.40358293,\n",
       "        0.39697197,  0.39968503,  0.3979343 ,  0.39663902,  0.40070218,\n",
       "        0.3963579 ,  0.4023438 ,  0.39598942,  0.3927418 ,  0.3964743 ,\n",
       "        0.39472422,  0.4012474 ,  0.38972166,  0.39879733,  0.39790878,\n",
       "        0.40271622,  0.40130672,  0.3970316 ,  0.40398479,  0.39908707,\n",
       "        0.40161148,  0.3931723 ,  0.3983135 ,  0.40291023,  0.39371896,\n",
       "        0.39525166,  0.40266606,  0.39908463,  0.392724  ,  0.4016079 ,\n",
       "        0.4030958 ,  0.39829707,  0.40413997,  0.39462867,  0.39624307,\n",
       "        0.3972426 ,  0.39915612,  0.39489985,  0.3970929 ,  0.3936337 ,\n",
       "        0.39381722,  0.39882824,  0.392491  ,  0.39299497,  0.396039  ,\n",
       "        0.3942573 ,  0.38921538,  0.38980982,  0.39557558,  0.39463034,\n",
       "        0.40371767,  0.39898086,  0.39864597,  0.3985176 ,  0.40177512,\n",
       "        0.40295455,  0.40089852,  0.3962284 ,  0.39899087,  0.3970437 ,\n",
       "        0.40488634,  0.39098793,  0.39764047,  0.39534363,  0.39953452,\n",
       "        0.39861068,  0.39518702, -0.02190346,  0.39604878,  0.39194945,\n",
       "        0.3981394 ,  0.396744  ,  0.39528129,  0.39954117,  0.40321004,\n",
       "        0.3955254 ,  0.39830908,  0.39406934,  0.3972148 ,  0.39621997,\n",
       "        0.3923443 ,  0.394411  ,  0.393977  ,  0.39684695,  0.39810026,\n",
       "        0.39450842,  0.39106983, -0.15601993,  0.39547288,  0.39797464,\n",
       "        0.39479712,  0.39561275,  0.39614385,  0.39815605,  0.39447927,\n",
       "        0.39421582,  0.3928444 ,  0.40594247,  0.39319953,  0.39737415,\n",
       "        0.39286035,  0.38920656,  0.39897025,  0.3952621 ,  0.39553016,\n",
       "        0.38838163,  0.39023072,  0.39289263,  0.39618564,  0.39026883,\n",
       "        0.39526656,  0.39907214,  0.40096214,  0.39586118,  0.39852858,\n",
       "        0.39178687,  0.40170255,  0.40824863,  0.4010783 ,  0.4008898 ,\n",
       "        0.40331656, -0.202241  ,  0.3958871 ,  0.399396  ,  0.4000515 ,\n",
       "        0.39012158,  0.39544526,  0.40139735,  0.39040402,  0.39192364,\n",
       "        0.3906184 ,  0.39420554,  0.39383733,  0.39062586,  0.39716116,\n",
       "        0.39780322,  0.39666528,  0.4033004 ,  0.3986522 ,  0.39642304,\n",
       "        0.3989024 ,  0.40313107,  0.39778656,  0.39285076,  0.39548203,\n",
       "        0.40008673,  0.38782817,  0.3946926 ,  0.39507335,  0.39492825,\n",
       "        0.3922951 ,  0.39147457,  0.3943025 ,  0.39099967,  0.3942202 ,\n",
       "        0.39259174,  0.3983639 ,  0.39208466,  0.39301142,  0.38968027,\n",
       "        0.39036915,  0.39361823,  0.39509284,  0.39691123,  0.39005342,\n",
       "        0.39153397,  0.39353007,  0.39489505,  0.39053878,  0.39887968,\n",
       "        0.39714593,  0.3938948 ,  0.39334545,  0.40117398,  0.39638618,\n",
       "        0.39946577,  0.39383432,  0.39226508,  0.3928589 ,  0.39429277,\n",
       "        0.39896637,  0.3914993 ,  0.39448562,  0.3922692 ,  0.39521146,\n",
       "        0.39929   ,  0.39444923,  0.39082697,  0.39102867,  0.3927364 ,\n",
       "        0.38958228,  0.39158714,  0.39496905,  0.38859314,  0.39589268,\n",
       "        0.39589667,  0.402658  ,  0.39926463,  0.39352736,  0.3944218 ,\n",
       "        0.3959434 ,  0.3973641 ,  0.3983653 ,  0.3965218 , -0.14711604,\n",
       "        0.3947147 ,  0.39234748,  0.3961961 ,  0.39671588,  0.3991635 ,\n",
       "        0.3957059 ,  0.39438155,  0.38793647, -0.10708567,  0.39075407],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 14 ms\n"
     ]
    }
   ],
   "source": [
    "print(x[0])\n",
    "decoded_output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f4b252131594fe7afd945962d95f55d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x2e2920499e8>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 30.9 ms\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib widget\n",
    "q=400\n",
    "plt.scatter(range(250),x[q],label=1)\n",
    "plt.scatter(range(250),decoded_output[q],label=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
